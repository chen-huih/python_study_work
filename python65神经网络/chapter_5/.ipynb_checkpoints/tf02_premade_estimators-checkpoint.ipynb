{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 10)\n",
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n",
      "age\n",
      "fare\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            #categorical_column_with_vocabulary_list可以直接看官网\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "for categorical_column in numeric_columns:\n",
    "    print(categorical_column)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            categorical_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'sex': <tf.Tensor: shape=(), dtype=string, numpy=b'male'>, 'age': <tf.Tensor: shape=(), dtype=float64, numpy=22.0>, 'n_siblings_spouses': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'parch': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'fare': <tf.Tensor: shape=(), dtype=float64, numpy=7.25>, 'class': <tf.Tensor: shape=(), dtype=string, numpy=b'Third'>, 'deck': <tf.Tensor: shape=(), dtype=string, numpy=b'unknown'>, 'embark_town': <tf.Tensor: shape=(), dtype=string, numpy=b'Southampton'>, 'alone': <tf.Tensor: shape=(), dtype=string, numpy=b'n'>}, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(train_df), y_train))\n",
    "\n",
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
    "                 batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    #必须是repeat类型的dataset，进行分批\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'linear_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/luke/.virtualenvs/tf_py3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/luke/.virtualenvs/tf_py3/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /home/luke/.virtualenvs/tf_py3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/luke/.virtualenvs/tf_py3/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model/model.ckpt-1960\n",
      "WARNING:tensorflow:From /home/luke/.virtualenvs/tf_py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1960...\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into linear_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1960...\n",
      "INFO:tensorflow:loss = 0.42471904, step = 1960\n",
      "INFO:tensorflow:global_step/sec: 234.003\n",
      "INFO:tensorflow:loss = 0.2950912, step = 2060 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.228\n",
      "INFO:tensorflow:loss = 0.30228257, step = 2160 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.236\n",
      "INFO:tensorflow:loss = 0.34115833, step = 2260 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.785\n",
      "INFO:tensorflow:loss = 0.52403355, step = 2360 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.746\n",
      "INFO:tensorflow:loss = 0.5204605, step = 2460 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.144\n",
      "INFO:tensorflow:loss = 0.36197013, step = 2560 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.061\n",
      "INFO:tensorflow:loss = 0.4960196, step = 2660 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.064\n",
      "INFO:tensorflow:loss = 0.42788404, step = 2760 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.438\n",
      "INFO:tensorflow:loss = 0.5593162, step = 2860 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.503\n",
      "INFO:tensorflow:loss = 0.41566765, step = 2960 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.981\n",
      "INFO:tensorflow:loss = 0.2745016, step = 3060 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.731\n",
      "INFO:tensorflow:loss = 0.3521616, step = 3160 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.901\n",
      "INFO:tensorflow:loss = 0.38147438, step = 3260 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.454\n",
      "INFO:tensorflow:loss = 0.23199975, step = 3360 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.72\n",
      "INFO:tensorflow:loss = 0.31536496, step = 3460 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.703\n",
      "INFO:tensorflow:loss = 0.52982384, step = 3560 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.896\n",
      "INFO:tensorflow:loss = 0.56389827, step = 3660 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.52\n",
      "INFO:tensorflow:loss = 0.5484832, step = 3760 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.873\n",
      "INFO:tensorflow:loss = 0.16053247, step = 3860 (0.194 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3920...\n",
      "INFO:tensorflow:Saving checkpoints for 3920 into linear_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3920...\n",
      "INFO:tensorflow:Loss for final step: 0.24341768.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x7fe2bdfefbe0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output_dir = 'linear_model'\n",
    "if not os.path.exists(linear_output_dir):\n",
    "    os.mkdir(linear_output_dir)\n",
    "#线性分类器模型\n",
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    model_dir = linear_output_dir,\n",
    "    n_classes = 2,\n",
    "    #之前定义好的feature_columns传入\n",
    "    feature_columns = feature_columns)\n",
    "linear_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global_step',\n",
       " 'linear/linear_model/age/weights',\n",
       " 'linear/linear_model/alone_indicator/weights',\n",
       " 'linear/linear_model/bias_weights',\n",
       " 'linear/linear_model/class_indicator/weights',\n",
       " 'linear/linear_model/deck_indicator/weights',\n",
       " 'linear/linear_model/embark_town_indicator/weights',\n",
       " 'linear/linear_model/fare/weights',\n",
       " 'linear/linear_model/n_siblings_spouses_indicator/weights',\n",
       " 'linear/linear_model/parch_indicator/weights',\n",
       " 'linear/linear_model/sex_indicator/weights',\n",
       " 'training/Ftrl/decay',\n",
       " 'training/Ftrl/l1_regularization_strength',\n",
       " 'training/Ftrl/l2_regularization_strength',\n",
       " 'training/Ftrl/learning_rate',\n",
       " 'training/Ftrl/learning_rate_power',\n",
       " 'training/Ftrl/linear/linear_model/age/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/age/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/alone_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/alone_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/bias_weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/bias_weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/class_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/class_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/deck_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/deck_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/embark_town_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/embark_town_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/fare/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/fare/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/n_siblings_spouses_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/n_siblings_spouses_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/parch_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/parch_indicator/weights/linear',\n",
       " 'training/Ftrl/linear/linear_model/sex_indicator/weights/accumulator',\n",
       " 'training/Ftrl/linear/linear_model/sex_indicator/weights/linear']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2879492 ],\n",
       "       [-2.9463675 ],\n",
       "       [-1.4032975 ],\n",
       "       [ 1.2244579 ],\n",
       "       [-0.91094524],\n",
       "       [ 2.236593  ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('training/Ftrl/linear/linear_model/parch_indicator/weights/linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.7724013],\n",
       "       [4.0160937]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('training/Ftrl/linear/linear_model/sex_indicator/weights/accumulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 1648\r\n",
      "-rw-rw-r-- 1 luke luke    130 May  7 15:11 checkpoint\r\n",
      "-rw-rw-r-- 1 luke luke 925955 May  7 15:11 graph.pbtxt\r\n",
      "-rw-rw-r-- 1 luke luke    448 May  7 15:11 model.ckpt-0.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 luke luke   1777 May  7 15:11 model.ckpt-0.index\r\n",
      "-rw-rw-r-- 1 luke luke 367755 May  7 15:11 model.ckpt-0.meta\r\n",
      "-rw-rw-r-- 1 luke luke    448 May  7 15:11 model.ckpt-1960.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 luke luke   1777 May  7 15:11 model.ckpt-1960.index\r\n",
      "-rw-rw-r-- 1 luke luke 367755 May  7 15:11 model.ckpt-1960.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-05-03T15:29:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model/model.ckpt-3920\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.02220s\n",
      "INFO:tensorflow:Finished evaluation at 2022-05-03-15:29:14\n",
      "INFO:tensorflow:Saving dict for global step 3920: accuracy = 0.78409094, accuracy_baseline = 0.625, auc = 0.83752674, auc_precision_recall = 0.7863668, average_loss = 0.48858187, global_step = 3920, label/mean = 0.375, loss = 0.4695381, precision = 0.68421054, prediction/mean = 0.43869576, recall = 0.7878788\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3920: linear_model/model.ckpt-3920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78409094,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.83752674,\n",
       " 'auc_precision_recall': 0.7863668,\n",
       " 'average_loss': 0.48858187,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.4695381,\n",
       " 'precision': 0.68421054,\n",
       " 'prediction/mean': 0.43869576,\n",
       " 'recall': 0.7878788,\n",
       " 'global_step': 3920}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter_5.tar.gz\tlinear_model_new_features\r\n",
      "data\t\t\ttf01_keras_to_estimator.ipynb\r\n",
      "dnn_model_new_features\ttf02_premade_estimators.ipynb\r\n",
      "linear_model\t\ttf03_premade_estimators-new_feature.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf dnn_model\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './dnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.6322014, step = 0\n",
      "INFO:tensorflow:global_step/sec: 237.12\n",
      "INFO:tensorflow:loss = 0.5571979, step = 100 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.315\n",
      "INFO:tensorflow:loss = 0.3986107, step = 200 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.942\n",
      "INFO:tensorflow:loss = 0.5636593, step = 300 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.73\n",
      "INFO:tensorflow:loss = 0.52206117, step = 400 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.872\n",
      "INFO:tensorflow:loss = 0.44467402, step = 500 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.866\n",
      "INFO:tensorflow:loss = 0.3983826, step = 600 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.819\n",
      "INFO:tensorflow:loss = 0.81329596, step = 700 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.96\n",
      "INFO:tensorflow:loss = 0.23748438, step = 800 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.552\n",
      "INFO:tensorflow:loss = 0.36638165, step = 900 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.358\n",
      "INFO:tensorflow:loss = 0.50842476, step = 1000 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.239\n",
      "INFO:tensorflow:loss = 0.37315345, step = 1100 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.809\n",
      "INFO:tensorflow:loss = 0.35417235, step = 1200 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.415\n",
      "INFO:tensorflow:loss = 0.5182638, step = 1300 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.73\n",
      "INFO:tensorflow:loss = 0.37471807, step = 1400 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.022\n",
      "INFO:tensorflow:loss = 0.2275024, step = 1500 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.624\n",
      "INFO:tensorflow:loss = 0.5188745, step = 1600 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.122\n",
      "INFO:tensorflow:loss = 0.26525182, step = 1700 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.227\n",
      "INFO:tensorflow:loss = 0.31461638, step = 1800 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.551\n",
      "INFO:tensorflow:loss = 0.35792813, step = 1900 (0.376 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1960...\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into ./dnn_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1960...\n",
      "INFO:tensorflow:Loss for final step: 0.3803608.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fe1f2f3a898>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下面是使用dnn估计器\n",
    "dnn_output_dir = './dnn_model'\n",
    "if not os.path.exists(dnn_output_dir):\n",
    "    os.mkdir(dnn_output_dir)\n",
    "#创建dnn估计器\n",
    "dnn_estimator = tf.estimator.DNNClassifier(\n",
    "    model_dir = dnn_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns=feature_columns,\n",
    "    #因为是dnn，我们定义层，两层，每一层是128\n",
    "    hidden_units = [128, 128,128],\n",
    "    #激活函数\n",
    "    activation_fn = tf.nn.relu,\n",
    "    #在Linear也有这个参数，只不过默认的，我们没有设置\n",
    "    optimizer = 'Adam')\n",
    "#开始训练\n",
    "dnn_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dnn/hiddenlayer_0/bias',\n",
       " 'dnn/hiddenlayer_0/kernel',\n",
       " 'dnn/hiddenlayer_1/bias',\n",
       " 'dnn/hiddenlayer_1/kernel',\n",
       " 'dnn/hiddenlayer_2/bias',\n",
       " 'dnn/hiddenlayer_2/kernel',\n",
       " 'dnn/logits/bias',\n",
       " 'dnn/logits/kernel',\n",
       " 'global_step',\n",
       " 'training/Adam/beta_1',\n",
       " 'training/Adam/beta_2',\n",
       " 'training/Adam/decay',\n",
       " 'training/Adam/dnn/hiddenlayer_0/bias/m',\n",
       " 'training/Adam/dnn/hiddenlayer_0/bias/v',\n",
       " 'training/Adam/dnn/hiddenlayer_0/kernel/m',\n",
       " 'training/Adam/dnn/hiddenlayer_0/kernel/v',\n",
       " 'training/Adam/dnn/hiddenlayer_1/bias/m',\n",
       " 'training/Adam/dnn/hiddenlayer_1/bias/v',\n",
       " 'training/Adam/dnn/hiddenlayer_1/kernel/m',\n",
       " 'training/Adam/dnn/hiddenlayer_1/kernel/v',\n",
       " 'training/Adam/dnn/hiddenlayer_2/bias/m',\n",
       " 'training/Adam/dnn/hiddenlayer_2/bias/v',\n",
       " 'training/Adam/dnn/hiddenlayer_2/kernel/m',\n",
       " 'training/Adam/dnn/hiddenlayer_2/kernel/v',\n",
       " 'training/Adam/dnn/logits/bias/m',\n",
       " 'training/Adam/dnn/logits/bias/v',\n",
       " 'training/Adam/dnn/logits/kernel/m',\n",
       " 'training/Adam/dnn/logits/kernel/v',\n",
       " 'training/Adam/learning_rate']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.get_variable_value('training/Adam/dnn/hiddenlayer_0/kernel/m').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-05-03T16:15:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.91049s\n",
      "INFO:tensorflow:Finished evaluation at 2022-05-03-16:15:41\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.81060606, accuracy_baseline = 0.625, auc = 0.8351087, auc_precision_recall = 0.7745796, average_loss = 0.5145089, global_step = 1960, label/mean = 0.375, loss = 0.4921469, precision = 0.7752809, prediction/mean = 0.35656777, recall = 0.6969697\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: ./dnn_model/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.81060606,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.8351087,\n",
       " 'auc_precision_recall': 0.7745796,\n",
       " 'average_loss': 0.5145089,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.4921469,\n",
       " 'precision': 0.7752809,\n",
       " 'prediction/mean': 0.35656777,\n",
       " 'recall': 0.6969697,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估\n",
    "dnn_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
