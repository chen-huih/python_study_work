{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, LogisticRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, classification_report, roc_auc_score\n",
    "# jblib用来保存机器学习的模型，把各个参数保存到磁盘上，使用时加载\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取特征值\n",
      "--------------------------------------------------\n",
      "(379, 13)\n",
      "[[20.6]\n",
      " [23.1]\n",
      " [28. ]\n",
      " [20. ]\n",
      " [23.1]\n",
      " [25. ]\n",
      " [ 9.7]\n",
      " [23.9]\n",
      " [36.1]\n",
      " [13.4]\n",
      " [12.7]\n",
      " [39.8]\n",
      " [10.4]\n",
      " [20.6]\n",
      " [17.8]\n",
      " [19.5]\n",
      " [23.7]\n",
      " [28.5]\n",
      " [24.3]\n",
      " [23.8]\n",
      " [19.1]\n",
      " [28.4]\n",
      " [20.5]\n",
      " [33.8]\n",
      " [14.5]\n",
      " [20.4]\n",
      " [16. ]\n",
      " [13.3]\n",
      " [30.8]\n",
      " [27.5]\n",
      " [24.4]\n",
      " [24.4]\n",
      " [25.1]\n",
      " [43.8]\n",
      " [21.9]\n",
      " [26.2]\n",
      " [14.2]\n",
      " [20.8]\n",
      " [20.1]\n",
      " [23.1]\n",
      " [13.1]\n",
      " [16.2]\n",
      " [24.8]\n",
      " [20.2]\n",
      " [22.5]\n",
      " [14.8]\n",
      " [28.7]\n",
      " [20.1]\n",
      " [23.4]\n",
      " [32. ]\n",
      " [19.1]\n",
      " [50. ]\n",
      " [20.9]\n",
      " [21.7]\n",
      " [22. ]\n",
      " [17.2]\n",
      " [30.3]\n",
      " [12.3]\n",
      " [21.4]\n",
      " [20.5]\n",
      " [35.2]\n",
      " [19.6]\n",
      " [22. ]\n",
      " [21.7]\n",
      " [14.1]\n",
      " [21.1]\n",
      " [15. ]\n",
      " [11.9]\n",
      " [20. ]\n",
      " [41.3]\n",
      " [18.7]\n",
      " [50. ]\n",
      " [50. ]\n",
      " [18.4]\n",
      " [17.9]\n",
      " [28.1]\n",
      " [16.1]\n",
      " [17.2]\n",
      " [28.6]\n",
      " [23.6]\n",
      " [20.4]\n",
      " [19.6]\n",
      " [18.8]\n",
      " [22.6]\n",
      " [17.7]\n",
      " [30.5]\n",
      " [18.2]\n",
      " [20.6]\n",
      " [24.4]\n",
      " [17.3]\n",
      " [13.3]\n",
      " [22.8]\n",
      " [20.5]\n",
      " [21.2]\n",
      " [18.8]\n",
      " [18.9]\n",
      " [18.2]\n",
      " [23.1]\n",
      " [32.7]\n",
      " [24. ]\n",
      " [10.2]\n",
      " [19.5]\n",
      " [33.1]\n",
      " [13.4]\n",
      " [15.2]\n",
      " [24.8]\n",
      " [24.3]\n",
      " [ 9.5]\n",
      " [24.2]\n",
      " [18.5]\n",
      " [44. ]\n",
      " [50. ]\n",
      " [24.7]\n",
      " [21.5]\n",
      " [ 8.4]\n",
      " [21.8]\n",
      " [50. ]\n",
      " [23.8]\n",
      " [32.4]\n",
      " [24.4]\n",
      " [17.6]\n",
      " [29.8]\n",
      " [ 9.6]\n",
      " [16.7]\n",
      " [13.8]\n",
      " [32. ]\n",
      " [16.1]\n",
      " [ 8.3]\n",
      " [26.6]\n",
      " [14.3]\n",
      " [15. ]\n",
      " [28.4]\n",
      " [32.2]\n",
      " [17.1]\n",
      " [29.4]\n",
      " [10.4]\n",
      " [16.8]\n",
      " [31.5]\n",
      " [27.5]\n",
      " [46.7]\n",
      " [27.5]\n",
      " [17.2]\n",
      " [23.4]\n",
      " [31.6]\n",
      " [13.8]\n",
      " [22. ]\n",
      " [17. ]\n",
      " [24.8]\n",
      " [24.3]\n",
      " [25.2]\n",
      " [21.2]\n",
      " [20.6]\n",
      " [18.7]\n",
      " [ 5.6]\n",
      " [19.3]\n",
      " [19.8]\n",
      " [22.3]\n",
      " [20.3]\n",
      " [12. ]\n",
      " [23.9]\n",
      " [16.5]\n",
      " [13.2]\n",
      " [33.2]\n",
      " [10.5]\n",
      " [ 7.5]\n",
      " [27.5]\n",
      " [18.4]\n",
      " [23.2]\n",
      " [13.8]\n",
      " [35.4]\n",
      " [23. ]\n",
      " [25. ]\n",
      " [ 7.2]\n",
      " [14.4]\n",
      " [ 8.8]\n",
      " [22.7]\n",
      " [13.1]\n",
      " [18.9]\n",
      " [25. ]\n",
      " [ 8.5]\n",
      " [16.1]\n",
      " [29. ]\n",
      " [23.1]\n",
      " [19.3]\n",
      " [33.1]\n",
      " [24.6]\n",
      " [23. ]\n",
      " [15.2]\n",
      " [27.1]\n",
      " [19.6]\n",
      " [24.5]\n",
      " [20.3]\n",
      " [34.9]\n",
      " [17.1]\n",
      " [15.6]\n",
      " [26.4]\n",
      " [22.6]\n",
      " [15.6]\n",
      " [29. ]\n",
      " [21.2]\n",
      " [22.4]\n",
      " [13.5]\n",
      " [11.7]\n",
      " [17.1]\n",
      " [31.7]\n",
      " [28.7]\n",
      " [24.7]\n",
      " [19. ]\n",
      " [ 7.2]\n",
      " [13.8]\n",
      " [12.8]\n",
      " [36.2]\n",
      " [38.7]\n",
      " [18.5]\n",
      " [29.1]\n",
      " [20.4]\n",
      " [11.3]\n",
      " [17.4]\n",
      " [ 8.7]\n",
      " [18.9]\n",
      " [23.2]\n",
      " [22.2]\n",
      " [29.1]\n",
      " [34.6]\n",
      " [25. ]\n",
      " [23.2]\n",
      " [37.9]\n",
      " [ 7. ]\n",
      " [18.2]\n",
      " [19.3]\n",
      " [26.7]\n",
      " [19.2]\n",
      " [30.1]\n",
      " [20.6]\n",
      " [50. ]\n",
      " [18.7]\n",
      " [20.6]\n",
      " [31.1]\n",
      " [14. ]\n",
      " [17.8]\n",
      " [42.3]\n",
      " [15.3]\n",
      " [18.5]\n",
      " [21.4]\n",
      " [15. ]\n",
      " [20.7]\n",
      " [21.4]\n",
      " [21.7]\n",
      " [22. ]\n",
      " [31.6]\n",
      " [22. ]\n",
      " [10.2]\n",
      " [22.6]\n",
      " [20. ]\n",
      " [17.8]\n",
      " [13.6]\n",
      " [11.8]\n",
      " [19.4]\n",
      " [21.4]\n",
      " [32.9]\n",
      " [20.8]\n",
      " [31. ]\n",
      " [17.5]\n",
      " [15.4]\n",
      " [10.8]\n",
      " [34.7]\n",
      " [25. ]\n",
      " [48.8]\n",
      " [42.8]\n",
      " [19.5]\n",
      " [30.1]\n",
      " [22.2]\n",
      " [50. ]\n",
      " [23.1]\n",
      " [32.5]\n",
      " [19.6]\n",
      " [14.9]\n",
      " [26.4]\n",
      " [37. ]\n",
      " [24.1]\n",
      " [24.5]\n",
      " [23.7]\n",
      " [ 7. ]\n",
      " [22.2]\n",
      " [23.3]\n",
      " [15.6]\n",
      " [13.4]\n",
      " [30.7]\n",
      " [22.3]\n",
      " [17.4]\n",
      " [50. ]\n",
      " [22.9]\n",
      " [19.7]\n",
      " [15.6]\n",
      " [17.8]\n",
      " [10.9]\n",
      " [35.1]\n",
      " [15.7]\n",
      " [50. ]\n",
      " [22.8]\n",
      " [19.9]\n",
      " [20.1]\n",
      " [19.4]\n",
      " [46. ]\n",
      " [23.2]\n",
      " [37.6]\n",
      " [23.1]\n",
      " [13.9]\n",
      " [33.3]\n",
      " [33. ]\n",
      " [19.9]\n",
      " [20.3]\n",
      " [50. ]\n",
      " [19.4]\n",
      " [19.5]\n",
      " [22.8]\n",
      " [16.6]\n",
      " [20. ]\n",
      " [24.7]\n",
      " [45.4]\n",
      " [33.4]\n",
      " [21.4]\n",
      " [19.4]\n",
      " [ 5. ]\n",
      " [ 7.4]\n",
      " [20.1]\n",
      " [12.7]\n",
      " [20.3]\n",
      " [14.1]\n",
      " [18.3]\n",
      " [19.9]\n",
      " [23.3]\n",
      " [36.5]\n",
      " [20. ]\n",
      " [17.8]\n",
      " [ 8.8]\n",
      " [21.6]\n",
      " [21.6]\n",
      " [15.2]\n",
      " [19.8]\n",
      " [21. ]\n",
      " [27.1]\n",
      " [16.8]\n",
      " [14.4]\n",
      " [22.5]\n",
      " [18.6]\n",
      " [20.1]\n",
      " [19.6]\n",
      " [25. ]\n",
      " [17.4]\n",
      " [19.7]\n",
      " [ 5. ]\n",
      " [16.3]\n",
      " [13.1]\n",
      " [29.6]\n",
      " [13.1]\n",
      " [19.1]\n",
      " [12.1]\n",
      " [21.7]\n",
      " [21.9]\n",
      " [33.2]\n",
      " [29.9]\n",
      " [35.4]\n",
      " [15.1]\n",
      " [31.5]\n",
      " [21.7]\n",
      " [16.4]\n",
      " [14.3]\n",
      " [11.8]\n",
      " [14.1]\n",
      " [21.1]\n",
      " [18.4]\n",
      " [48.5]\n",
      " [13.8]\n",
      " [20.9]\n",
      " [22.8]\n",
      " [12.5]\n",
      " [24. ]\n",
      " [21. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-0.19582006],\n       [ 0.0847902 ],\n       [ 0.63478631],\n       [-0.26316652],\n       [ 0.0847902 ],\n       [ 0.298054  ],\n       [-1.41928078],\n       [ 0.17458549],\n       [ 1.54396354],\n       [-1.0039776 ],\n       [-1.08254847],\n       [ 1.95926673],\n       [-1.34070991],\n       [-0.19582006],\n       [-0.51010354],\n       [-0.31928857],\n       [ 0.15213666],\n       [ 0.69090836],\n       [ 0.21948313],\n       [ 0.16336107],\n       [-0.36418621],\n       [ 0.67968395],\n       [-0.20704447],\n       [ 1.28580211],\n       [-0.88050909],\n       [-0.21826888],\n       [-0.71214293],\n       [-1.01520201],\n       [ 0.9490698 ],\n       [ 0.57866426],\n       [ 0.23070754],\n       [ 0.23070754],\n       [ 0.30927841],\n       [ 2.40824314],\n       [-0.04990272],\n       [ 0.43274692],\n       [-0.91418232],\n       [-0.17337123],\n       [-0.25194211],\n       [ 0.0847902 ],\n       [-1.03765083],\n       [-0.68969411],\n       [ 0.27560518],\n       [-0.2407177 ],\n       [ 0.01744374],\n       [-0.84683585],\n       [ 0.71335718],\n       [-0.25194211],\n       [ 0.11846343],\n       [ 1.08376272],\n       [-0.36418621],\n       [ 3.10415658],\n       [-0.16214682],\n       [-0.07235154],\n       [-0.03867831],\n       [-0.57745001],\n       [ 0.89294775],\n       [-1.12744611],\n       [-0.10602477],\n       [-0.20704447],\n       [ 1.44294385],\n       [-0.30806416],\n       [-0.03867831],\n       [-0.07235154],\n       [-0.92540673],\n       [-0.139698  ],\n       [-0.82438703],\n       [-1.17234375],\n       [-0.26316652],\n       [ 2.12763288],\n       [-0.40908385],\n       [ 3.10415658],\n       [ 3.10415658],\n       [-0.44275708],\n       [-0.49887913],\n       [ 0.64601072],\n       [-0.70091852],\n       [-0.57745001],\n       [ 0.70213277],\n       [ 0.14091225],\n       [-0.21826888],\n       [-0.30806416],\n       [-0.39785944],\n       [ 0.02866815],\n       [-0.52132795],\n       [ 0.91539657],\n       [-0.4652059 ],\n       [-0.19582006],\n       [ 0.23070754],\n       [-0.5662256 ],\n       [-1.01520201],\n       [ 0.05111697],\n       [-0.20704447],\n       [-0.12847359],\n       [-0.39785944],\n       [-0.38663503],\n       [-0.4652059 ],\n       [ 0.0847902 ],\n       [ 1.16233359],\n       [ 0.1858099 ],\n       [-1.36315873],\n       [-0.31928857],\n       [ 1.20723123],\n       [-1.0039776 ],\n       [-0.80193821],\n       [ 0.27560518],\n       [ 0.21948313],\n       [-1.4417296 ],\n       [ 0.20825872],\n       [-0.43153267],\n       [ 2.43069196],\n       [ 3.10415658],\n       [ 0.26438077],\n       [-0.09480036],\n       [-1.56519811],\n       [-0.06112713],\n       [ 3.10415658],\n       [ 0.16336107],\n       [ 1.12866036],\n       [ 0.23070754],\n       [-0.53255237],\n       [ 0.83682569],\n       [-1.43050519],\n       [-0.63357206],\n       [-0.95907996],\n       [ 1.08376272],\n       [-0.70091852],\n       [-1.57642252],\n       [ 0.47764456],\n       [-0.90295791],\n       [-0.82438703],\n       [ 0.67968395],\n       [ 1.10621154],\n       [-0.58867442],\n       [ 0.79192805],\n       [-1.34070991],\n       [-0.62234765],\n       [ 1.02764067],\n       [ 0.57866426],\n       [ 2.73375104],\n       [ 0.57866426],\n       [-0.57745001],\n       [ 0.11846343],\n       [ 1.03886508],\n       [-0.95907996],\n       [-0.03867831],\n       [-0.59989883],\n       [ 0.27560518],\n       [ 0.21948313],\n       [ 0.32050282],\n       [-0.12847359],\n       [-0.19582006],\n       [-0.40908385],\n       [-1.8794816 ],\n       [-0.34173739],\n       [-0.28561534],\n       [-0.00500508],\n       [-0.22949329],\n       [-1.16111934],\n       [ 0.17458549],\n       [-0.65602088],\n       [-1.02642642],\n       [ 1.21845564],\n       [-1.3294855 ],\n       [-1.66621781],\n       [ 0.57866426],\n       [-0.44275708],\n       [ 0.09601461],\n       [-0.95907996],\n       [ 1.46539267],\n       [ 0.07356579],\n       [ 0.298054  ],\n       [-1.69989104],\n       [-0.8917335 ],\n       [-1.52030047],\n       [ 0.03989256],\n       [-1.03765083],\n       [-0.38663503],\n       [ 0.298054  ],\n       [-1.5539737 ],\n       [-0.70091852],\n       [ 0.74703041],\n       [ 0.0847902 ],\n       [-0.34173739],\n       [ 1.20723123],\n       [ 0.25315636],\n       [ 0.07356579],\n       [-0.80193821],\n       [ 0.53376662],\n       [-0.30806416],\n       [ 0.24193195],\n       [-0.22949329],\n       [ 1.40927062],\n       [-0.58867442],\n       [-0.75704057],\n       [ 0.45519574],\n       [ 0.02866815],\n       [-0.75704057],\n       [ 0.74703041],\n       [-0.12847359],\n       [ 0.00621933],\n       [-0.99275319],\n       [-1.19479257],\n       [-0.58867442],\n       [ 1.05008949],\n       [ 0.71335718],\n       [ 0.26438077],\n       [-0.37541062],\n       [-1.69989104],\n       [-0.95907996],\n       [-1.07132406],\n       [ 1.55518795],\n       [ 1.83579821],\n       [-0.43153267],\n       [ 0.75825482],\n       [-0.21826888],\n       [-1.23969022],\n       [-0.55500119],\n       [-1.53152488],\n       [-0.38663503],\n       [ 0.09601461],\n       [-0.01622949],\n       [ 0.75825482],\n       [ 1.37559739],\n       [ 0.298054  ],\n       [ 0.09601461],\n       [ 1.74600293],\n       [-1.72233986],\n       [-0.4652059 ],\n       [-0.34173739],\n       [ 0.48886897],\n       [-0.3529618 ],\n       [ 0.87049892],\n       [-0.19582006],\n       [ 3.10415658],\n       [-0.40908385],\n       [-0.19582006],\n       [ 0.98274303],\n       [-0.93663114],\n       [-0.51010354],\n       [ 2.23987698],\n       [-0.7907138 ],\n       [-0.43153267],\n       [-0.10602477],\n       [-0.82438703],\n       [-0.18459565],\n       [-0.10602477],\n       [-0.07235154],\n       [-0.03867831],\n       [ 1.03886508],\n       [-0.03867831],\n       [-1.36315873],\n       [ 0.02866815],\n       [-0.26316652],\n       [-0.51010354],\n       [-0.98152878],\n       [-1.18356816],\n       [-0.33051298],\n       [-0.10602477],\n       [ 1.18478241],\n       [-0.17337123],\n       [ 0.97151862],\n       [-0.54377678],\n       [-0.77948939],\n       [-1.29581227],\n       [ 1.3868218 ],\n       [ 0.298054  ],\n       [ 2.96946365],\n       [ 2.29599904],\n       [-0.31928857],\n       [ 0.87049892],\n       [-0.01622949],\n       [ 3.10415658],\n       [ 0.0847902 ],\n       [ 1.13988477],\n       [-0.30806416],\n       [-0.83561144],\n       [ 0.45519574],\n       [ 1.64498324],\n       [ 0.19703431],\n       [ 0.24193195],\n       [ 0.15213666],\n       [-1.72233986],\n       [-0.01622949],\n       [ 0.10723902],\n       [-0.75704057],\n       [-1.0039776 ],\n       [ 0.93784539],\n       [-0.00500508],\n       [-0.55500119],\n       [ 3.10415658],\n       [ 0.06234138],\n       [-0.29683975],\n       [-0.75704057],\n       [-0.51010354],\n       [-1.28458786],\n       [ 1.43171944],\n       [-0.74581616],\n       [ 3.10415658],\n       [ 0.05111697],\n       [-0.27439093],\n       [-0.25194211],\n       [-0.33051298],\n       [ 2.65518017],\n       [ 0.09601461],\n       [ 1.7123297 ],\n       [ 0.0847902 ],\n       [-0.94785555],\n       [ 1.22968006],\n       [ 1.19600682],\n       [-0.27439093],\n       [-0.22949329],\n       [ 3.10415658],\n       [-0.33051298],\n       [-0.31928857],\n       [ 0.05111697],\n       [-0.64479647],\n       [-0.26316652],\n       [ 0.26438077],\n       [ 2.5878337 ],\n       [ 1.24090447],\n       [-0.10602477],\n       [-0.33051298],\n       [-1.94682807],\n       [-1.67744222],\n       [-0.25194211],\n       [-1.08254847],\n       [-0.22949329],\n       [-0.92540673],\n       [-0.45398149],\n       [-0.27439093],\n       [ 0.10723902],\n       [ 1.58886119],\n       [-0.26316652],\n       [-0.51010354],\n       [-1.52030047],\n       [-0.08357595],\n       [-0.08357595],\n       [-0.80193821],\n       [-0.28561534],\n       [-0.15092241],\n       [ 0.53376662],\n       [-0.62234765],\n       [-0.8917335 ],\n       [ 0.01744374],\n       [-0.42030826],\n       [-0.25194211],\n       [-0.30806416],\n       [ 0.298054  ],\n       [-0.55500119],\n       [-0.29683975],\n       [-1.94682807],\n       [-0.6784697 ],\n       [-1.03765083],\n       [ 0.81437687],\n       [-1.03765083],\n       [-0.36418621],\n       [-1.14989493],\n       [-0.07235154],\n       [-0.04990272],\n       [ 1.21845564],\n       [ 0.8480501 ],\n       [ 1.46539267],\n       [-0.81316262],\n       [ 1.02764067],\n       [-0.07235154],\n       [-0.66724529],\n       [-0.90295791],\n       [-1.18356816],\n       [-0.92540673],\n       [-0.139698  ],\n       [-0.44275708],\n       [ 2.93579042],\n       [-0.95907996],\n       [-0.16214682],\n       [ 0.05111697],\n       [-1.10499729],\n       [ 0.1858099 ],\n       [-0.15092241]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "线性回归直接预测房子价格\n",
    ":return: None\n",
    "\"\"\"\n",
    "# 获取数据,直接网上下载，数据量不多\n",
    "lb = load_boston()\n",
    "\n",
    "print(\"获取特征值\")\n",
    "# print(lb.data)\n",
    "# print(\"目标值\")\n",
    "# print(lb.target)\n",
    "# print(lb.DESCR)\n",
    "# print(lb.feature_names)\n",
    "print('-' * 50)\n",
    "# 分割数据集到训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(lb.data, lb.target, test_size=0.25, random_state=1)\n",
    "#\n",
    "print(x_train.shape)\n",
    "#\n",
    "# # 进行标准化处理(?) 目标值处理？\n",
    "# # 特征值和目标值是都必须进行标准化处理, 实例化两个标准化API\n",
    "std_x = StandardScaler()\n",
    "# 对数据进行处理\n",
    "x_train = std_x.fit_transform(x_train)\n",
    "x_test = std_x.transform(x_test)\n",
    "\n",
    "# 目标值进行了标准化\n",
    "std_y = StandardScaler()\n",
    "# 不管原来的是几维都变为一个只有一列的二维数组\n",
    "temp = y_train.reshape(-1, 1)\n",
    "# 输出还没标准化的房价\n",
    "print(temp)\n",
    "# 目标值是一维的，这里需要传进去2维的，标准化的fit_transform需要是二维的\n",
    "y_train = std_y.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# transform不再进行计算，使用上面的直接标准化\n",
    "y_test = std_y.transform(y_test.reshape(-1, 1))\n",
    "# 输出标准化后的目标房价\n",
    "y_train\n",
    "# 以上都是数据处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归系数 [[-0.12026411  0.15044778  0.02951803  0.07470354 -0.28043353  0.22170939\n",
      "   0.02190624 -0.35275513  0.29939558 -0.2028089  -0.23911894  0.06305081\n",
      "  -0.45259462]]\n",
      "正规方程测试集里面每个房子的预测价格： [[32.37816533]\n",
      " [27.95684437]\n",
      " [18.07213891]\n",
      " [21.63166556]\n",
      " [18.93029508]\n",
      " [19.96277202]\n",
      " [32.2834674 ]\n",
      " [18.06715668]\n",
      " [24.72989076]\n",
      " [26.85359369]\n",
      " [27.23326816]\n",
      " [28.57021239]\n",
      " [21.18778302]\n",
      " [26.94393815]\n",
      " [23.37892579]\n",
      " [20.89176865]\n",
      " [17.11746934]\n",
      " [37.73997945]\n",
      " [30.51980066]\n",
      " [ 8.44489436]\n",
      " [20.86557977]\n",
      " [16.21989418]\n",
      " [25.13605925]\n",
      " [24.77658813]\n",
      " [31.40497629]\n",
      " [11.02741407]\n",
      " [13.82097563]\n",
      " [16.80208261]\n",
      " [35.94637198]\n",
      " [14.7155729 ]\n",
      " [21.23939821]\n",
      " [14.15079469]\n",
      " [42.72492585]\n",
      " [17.83887162]\n",
      " [21.84610225]\n",
      " [20.40178099]\n",
      " [17.50287927]\n",
      " [27.00093206]\n",
      " [ 9.80760408]\n",
      " [20.00288662]\n",
      " [24.27066782]\n",
      " [21.06719021]\n",
      " [29.47089776]\n",
      " [16.48482565]\n",
      " [19.38852695]\n",
      " [14.54778282]\n",
      " [39.39838319]\n",
      " [18.09810655]\n",
      " [26.22164983]\n",
      " [20.60676525]\n",
      " [25.09994066]\n",
      " [24.48366723]\n",
      " [25.02297948]\n",
      " [26.84986898]\n",
      " [ 5.01517985]\n",
      " [24.12809513]\n",
      " [10.72843392]\n",
      " [26.83178157]\n",
      " [16.8023533 ]\n",
      " [35.48142073]\n",
      " [19.50937911]\n",
      " [27.43260347]\n",
      " [16.58016763]\n",
      " [19.151488  ]\n",
      " [10.9990262 ]\n",
      " [32.05016535]\n",
      " [36.32672849]\n",
      " [21.8596379 ]\n",
      " [24.8158357 ]\n",
      " [25.32934192]\n",
      " [23.36795453]\n",
      " [ 6.98356201]\n",
      " [16.83774771]\n",
      " [20.27043864]\n",
      " [20.74890857]\n",
      " [21.85918305]\n",
      " [34.17775836]\n",
      " [27.94673486]\n",
      " [24.86029952]\n",
      " [34.43415796]\n",
      " [18.61651831]\n",
      " [24.02302532]\n",
      " [34.45439496]\n",
      " [13.32264718]\n",
      " [20.7154011 ]\n",
      " [30.1583435 ]\n",
      " [17.06611728]\n",
      " [24.20119805]\n",
      " [19.18051951]\n",
      " [16.98160423]\n",
      " [26.8073424 ]\n",
      " [41.02666829]\n",
      " [14.44767989]\n",
      " [23.26993252]\n",
      " [14.93803206]\n",
      " [21.93017824]\n",
      " [22.81878103]\n",
      " [29.16467031]\n",
      " [36.7033389 ]\n",
      " [20.41387117]\n",
      " [17.86800518]\n",
      " [17.49942601]\n",
      " [25.07246443]\n",
      " [21.9827349 ]\n",
      " [ 8.28652561]\n",
      " [21.52177032]\n",
      " [16.50788716]\n",
      " [33.00114509]\n",
      " [24.49693379]\n",
      " [25.08491201]\n",
      " [38.29621948]\n",
      " [28.93273167]\n",
      " [14.85478187]\n",
      " [34.7429184 ]\n",
      " [35.50029467]\n",
      " [32.89599805]\n",
      " [20.98069467]\n",
      " [16.67849644]\n",
      " [34.24728954]\n",
      " [39.01179205]\n",
      " [21.57169864]\n",
      " [15.71337489]\n",
      " [27.33121768]\n",
      " [18.73350137]\n",
      " [27.27438226]\n",
      " [21.16402252]\n",
      " [26.00459084]]\n",
      "正规方程的均方误差： 0.2758842244225054\n"
     ]
    }
   ],
   "source": [
    "# # estimator预测\n",
    "# # # 正规方程求解方式预测结果，正规方程进行线性回归，这是一个正规方程的接口\n",
    "lr = LinearRegression()\n",
    "# #\n",
    "lr.fit(x_train, y_train)\n",
    "#\n",
    "print('回归系数', lr.coef_)  # 回归系数可以看特征与目标之间的相关性\n",
    "#\n",
    "y_predict = lr.predict(x_test)\n",
    "# 预测测试集的房子价格，通过inverse得到真正的房子价格，因为房价经过了标准化\n",
    "y_lr_predict = std_y.inverse_transform(y_predict)\n",
    "# 保存训练好的模型,模型参数就在lr里面\n",
    "joblib.dump(lr, \"./tmp/test.pkl\")\n",
    "print(\"正规方程测试集里面每个房子的预测价格：\", y_lr_predict)\n",
    "print(\"正规方程的均方误差：\", mean_squared_error(y_test, y_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 加载保存的模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存的模型预测的结果： [[ 1.12620955]\n",
      " [ 0.62994234]\n",
      " [-0.47955756]\n",
      " [-0.08002168]\n",
      " [-0.38323459]\n",
      " [-0.26734514]\n",
      " [ 1.11558027]\n",
      " [-0.48011678]\n",
      " [ 0.26773583]\n",
      " [ 0.50610896]\n",
      " [ 0.54872518]\n",
      " [ 0.69878929]\n",
      " [-0.12984488]\n",
      " [ 0.51624959]\n",
      " [ 0.11609798]\n",
      " [-0.16307075]\n",
      " [-0.58671359]\n",
      " [ 1.72804157]\n",
      " [ 0.91761907]\n",
      " [-1.56015899]\n",
      " [-0.16601029]\n",
      " [-0.68746111]\n",
      " [ 0.31332585]\n",
      " [ 0.27297733]\n",
      " [ 1.01697482]\n",
      " [-1.27028638]\n",
      " [-0.95672557]\n",
      " [-0.62211389]\n",
      " [ 1.5267197 ]\n",
      " [-0.8563123 ]\n",
      " [-0.12405138]\n",
      " [-0.91970532]\n",
      " [ 2.28757241]\n",
      " [-0.50574043]\n",
      " [-0.05595243]\n",
      " [-0.21806897]\n",
      " [-0.54345359]\n",
      " [ 0.52264682]\n",
      " [-1.40720286]\n",
      " [-0.26284251]\n",
      " [ 0.21619076]\n",
      " [-0.14338071]\n",
      " [ 0.79988591]\n",
      " [-0.65772411]\n",
      " [-0.33180076]\n",
      " [-0.87514574]\n",
      " [ 1.91418761]\n",
      " [-0.47664284]\n",
      " [ 0.43517699]\n",
      " [-0.1950607 ]\n",
      " [ 0.30927175]\n",
      " [ 0.24009869]\n",
      " [ 0.30063331]\n",
      " [ 0.50569088]\n",
      " [-1.94512422]\n",
      " [ 0.20018782]\n",
      " [-1.30384514]\n",
      " [ 0.50366068]\n",
      " [-0.6220835 ]\n",
      " [ 1.47453167]\n",
      " [-0.31823582]\n",
      " [ 0.57109939]\n",
      " [-0.64702253]\n",
      " [-0.35840699]\n",
      " [-1.27347275]\n",
      " [ 1.08939349]\n",
      " [ 1.56941248]\n",
      " [-0.05443313]\n",
      " [ 0.27738264]\n",
      " [ 0.33502069]\n",
      " [ 0.11486652]\n",
      " [-1.72418493]\n",
      " [-0.61811069]\n",
      " [-0.23281138]\n",
      " [-0.17910595]\n",
      " [-0.05448418]\n",
      " [ 1.32820326]\n",
      " [ 0.62880761]\n",
      " [ 0.28237344]\n",
      " [ 1.3569826 ]\n",
      " [-0.41845418]\n",
      " [ 0.18839435]\n",
      " [ 1.35925408]\n",
      " [-1.01266   ]\n",
      " [-0.18286696]\n",
      " [ 0.87704764]\n",
      " [-0.59247755]\n",
      " [ 0.20839319]\n",
      " [-0.35514837]\n",
      " [-0.60196364]\n",
      " [ 0.50091753]\n",
      " [ 2.09695301]\n",
      " [-0.88638171]\n",
      " [ 0.10386413]\n",
      " [-0.83134257]\n",
      " [-0.04651539]\n",
      " [ 0.05322503]\n",
      " [ 0.76551368]\n",
      " [ 1.61168478]\n",
      " [-0.21671192]\n",
      " [-0.50247036]\n",
      " [-0.5438412 ]\n",
      " [ 0.3061877 ]\n",
      " [-0.04061622]\n",
      " [-1.57793495]\n",
      " [-0.09235677]\n",
      " [-0.65513559]\n",
      " [ 1.19613535]\n",
      " [ 0.24158778]\n",
      " [ 0.30758487]\n",
      " [ 1.79047623]\n",
      " [ 0.73947994]\n",
      " [-0.84068691]\n",
      " [ 1.39163914]\n",
      " [ 1.47665016]\n",
      " [ 1.18433322]\n",
      " [-0.15308932]\n",
      " [-0.63598571]\n",
      " [ 1.33600772]\n",
      " [ 1.87079503]\n",
      " [-0.08675261]\n",
      " [-0.74431491]\n",
      " [ 0.55971944]\n",
      " [-0.40532352]\n",
      " [ 0.55334   ]\n",
      " [-0.13251185]\n",
      " [ 0.4108134 ]]\n",
      "正规方程的均方误差： 0.2758842244225054\n",
      "正规方程inverse后的均方误差： 21.89776539604949\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"./tmp/test.pkl\")\n",
    "# # 因为目标值进行了标准化，一定要把预测后的值逆向转换回来\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "#\n",
    "print(\"保存的模型预测的结果：\", y_predict)\n",
    "print(\"正规方程的均方误差：\", mean_squared_error(y_test, y_predict))\n",
    "\n",
    "print(\"正规方程inverse后的均方误差：\", mean_squared_error(std_y.inverse_transform(y_test),\n",
    "                                               std_y.inverse_transform(y_predict)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.375"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "mean_squared_error(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.375"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#人工求均方误差\n",
    "(np.square(3 - 2.5) + np.square(0.5) + 1) / 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "梯度下降的回归系数 [-0.09161381  0.07894594 -0.01997965  0.07736127 -0.18054122  0.26622108\n",
      "  0.         -0.23891603  0.09441201 -0.02523685 -0.22153748  0.06690733\n",
      " -0.4268276 ]\n",
      "梯度下降测试集里面每个房子的预测价格： [[30.32788625]\n",
      " [28.2472966 ]\n",
      " [18.30943245]\n",
      " [22.59556785]\n",
      " [18.35680256]\n",
      " [20.78684621]\n",
      " [30.24536495]\n",
      " [18.66209012]\n",
      " [23.78774605]\n",
      " [26.97567026]\n",
      " [26.37424819]\n",
      " [29.42246868]\n",
      " [21.60787196]\n",
      " [25.88755575]\n",
      " [23.02476327]\n",
      " [19.47432779]\n",
      " [16.92218956]\n",
      " [37.85566623]\n",
      " [29.94252206]\n",
      " [ 9.68559596]\n",
      " [20.93595383]\n",
      " [17.3629154 ]\n",
      " [25.40769352]\n",
      " [25.21312443]\n",
      " [30.55409234]\n",
      " [10.62699034]\n",
      " [14.44340854]\n",
      " [19.41367655]\n",
      " [35.63512925]\n",
      " [13.89827052]\n",
      " [23.99610575]\n",
      " [14.80961808]\n",
      " [40.63030223]\n",
      " [17.96567407]\n",
      " [24.16781208]\n",
      " [20.94382202]\n",
      " [17.53984421]\n",
      " [28.18178196]\n",
      " [ 8.09947878]\n",
      " [19.45922413]\n",
      " [26.43987001]\n",
      " [22.05015656]\n",
      " [28.68910453]\n",
      " [15.49251056]\n",
      " [18.56596167]\n",
      " [14.90704937]\n",
      " [39.74153394]\n",
      " [17.56879259]\n",
      " [25.86973592]\n",
      " [20.91672203]\n",
      " [24.75347158]\n",
      " [24.58762127]\n",
      " [25.75260948]\n",
      " [26.56115866]\n",
      " [ 7.40399189]\n",
      " [24.11368039]\n",
      " [10.47772936]\n",
      " [26.53516535]\n",
      " [17.55578551]\n",
      " [35.76241939]\n",
      " [19.33751744]\n",
      " [27.56878845]\n",
      " [15.82712147]\n",
      " [18.03991689]\n",
      " [11.05719455]\n",
      " [31.43250418]\n",
      " [36.69059399]\n",
      " [25.40593622]\n",
      " [24.62339777]\n",
      " [25.00785076]\n",
      " [24.15228553]\n",
      " [ 6.28699933]\n",
      " [15.60338113]\n",
      " [21.28938557]\n",
      " [20.84719257]\n",
      " [21.03884472]\n",
      " [33.01071092]\n",
      " [28.44076084]\n",
      " [26.39232619]\n",
      " [32.63054723]\n",
      " [19.35649801]\n",
      " [24.38105827]\n",
      " [34.56340583]\n",
      " [13.79024336]\n",
      " [23.20379641]\n",
      " [30.1511816 ]\n",
      " [17.05999409]\n",
      " [25.11417332]\n",
      " [19.71135144]\n",
      " [17.86719255]\n",
      " [27.10253233]\n",
      " [41.19045449]\n",
      " [17.02299072]\n",
      " [23.64766517]\n",
      " [15.09298067]\n",
      " [22.53785618]\n",
      " [23.31788344]\n",
      " [27.5546369 ]\n",
      " [36.56621953]\n",
      " [21.0425524 ]\n",
      " [16.63544719]\n",
      " [17.71054207]\n",
      " [25.53208005]\n",
      " [22.33824298]\n",
      " [ 7.81820917]\n",
      " [22.2813497 ]\n",
      " [15.01857284]\n",
      " [32.45028907]\n",
      " [23.79739852]\n",
      " [25.80431343]\n",
      " [37.88440039]\n",
      " [28.37259633]\n",
      " [14.46941887]\n",
      " [32.93882785]\n",
      " [34.90972314]\n",
      " [33.91422639]\n",
      " [21.04470171]\n",
      " [17.08443761]\n",
      " [33.13913623]\n",
      " [38.89891769]\n",
      " [23.49906608]\n",
      " [15.98457115]\n",
      " [28.13319007]\n",
      " [18.91961041]\n",
      " [26.90739063]\n",
      " [21.59354866]\n",
      " [25.98775391]]\n",
      "梯度下降的均方误差： 0.2782778128254135\n",
      "梯度下降的原始房价量纲均方误差： 22.087751747792876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 梯度下降去进行房价预测,数据量大要用这个\n",
    "# 默认可以去调 eta0 = 0.008，会改变learning_rate,默认0.01\n",
    "# learning_rate='invscaling'(eta=eta0/pow(t,power_t)),='constant'(学习率就是eta0)\n",
    "# 各个参数之间是有关联的\n",
    "# alpha会影响学习率的值，由alpha来算学习率\n",
    "# 下面学习率为0.008，正则化选择l1,正则化力度选择0.005\n",
    "sgd = SGDRegressor(eta0=0.008, penalty='l1', alpha=0.005)\n",
    "# # 训练\n",
    "sgd.fit(x_train, y_train)\n",
    "#\n",
    "print('梯度下降的回归系数', sgd.coef_)\n",
    "#\n",
    "# 预测测试集的房子价格，预测出的y是一维的，需要reshape\n",
    "y_sgd_predict = std_y.inverse_transform(sgd.predict(x_test).reshape(-1, 1))\n",
    "y_predict = sgd.predict(x_test)\n",
    "print(\"梯度下降测试集里面每个房子的预测价格：\", y_sgd_predict)\n",
    "print(\"梯度下降的均方误差：\", mean_squared_error(y_test, y_predict))\n",
    "print(\"梯度下降的原始房价量纲均方误差：\", mean_squared_error(std_y.inverse_transform(y_test), y_sgd_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#3 岭回归"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12019408  0.15027489  0.02932631  0.07472724 -0.28019156  0.22179958\n",
      "   0.0218258  -0.35250679  0.29879635 -0.20224632 -0.23906031  0.06305591\n",
      "  -0.45246484]]\n",
      "岭回归的均方误差： 0.27588055100713926\n",
      "岭回归的均方误差： 21.897473825960407\n"
     ]
    }
   ],
   "source": [
    "# # # 岭回归去进行房价预测\n",
    "rd = Ridge(alpha=0.05)\n",
    "\n",
    "rd.fit(x_train, y_train)\n",
    "\n",
    "print(rd.coef_)\n",
    "#\n",
    "# # 预测测试集的房子价格\n",
    "y_rd_predict = std_y.inverse_transform(rd.predict(x_test))\n",
    "y_predict = rd.predict(x_test)\n",
    "# print(\"岭回归里面每个房子的预测价格：\", y_rd_predict)\n",
    "#\n",
    "print(\"岭回归的均方误差：\", mean_squared_error(y_test, y_predict))\n",
    "print(\"岭回归的均方误差：\", mean_squared_error(std_y.inverse_transform(y_test), y_rd_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "-1.2039728043259361"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
      "0               1000025                5                        1   \n",
      "1               1002945                5                        4   \n",
      "2               1015425                3                        1   \n",
      "3               1016277                6                        8   \n",
      "4               1017023                4                        1   \n",
      "..                  ...              ...                      ...   \n",
      "694              776715                3                        1   \n",
      "695              841769                2                        1   \n",
      "696              888820                5                       10   \n",
      "697              897471                4                        8   \n",
      "698              897471                4                        8   \n",
      "\n",
      "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
      "0                           1                  1                            2   \n",
      "1                           4                  5                            7   \n",
      "2                           1                  1                            2   \n",
      "3                           8                  1                            3   \n",
      "4                           1                  3                            2   \n",
      "..                        ...                ...                          ...   \n",
      "694                         1                  1                            3   \n",
      "695                         1                  1                            2   \n",
      "696                        10                  3                            7   \n",
      "697                         6                  4                            3   \n",
      "698                         8                  5                            4   \n",
      "\n",
      "    Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
      "0             1                3                1        1      2  \n",
      "1            10                3                2        1      2  \n",
      "2             2                3                1        1      2  \n",
      "3             4                3                7        1      2  \n",
      "4             1                3                1        1      2  \n",
      "..          ...              ...              ...      ...    ...  \n",
      "694           2                1                1        1      2  \n",
      "695           1                1                1        1      2  \n",
      "696           3                8               10        2      4  \n",
      "697           4               10                6        1      4  \n",
      "698           5               10                4        1      4  \n",
      "\n",
      "[699 rows x 11 columns]\n",
      "--------------------------------------------------\n",
      "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
      "0               1000025                5                        1   \n",
      "1               1002945                5                        4   \n",
      "2               1015425                3                        1   \n",
      "3               1016277                6                        8   \n",
      "4               1017023                4                        1   \n",
      "..                  ...              ...                      ...   \n",
      "694              776715                3                        1   \n",
      "695              841769                2                        1   \n",
      "696              888820                5                       10   \n",
      "697              897471                4                        8   \n",
      "698              897471                4                        8   \n",
      "\n",
      "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
      "0                           1                  1                            2   \n",
      "1                           4                  5                            7   \n",
      "2                           1                  1                            2   \n",
      "3                           8                  1                            3   \n",
      "4                           1                  3                            2   \n",
      "..                        ...                ...                          ...   \n",
      "694                         1                  1                            3   \n",
      "695                         1                  1                            2   \n",
      "696                        10                  3                            7   \n",
      "697                         6                  4                            3   \n",
      "698                         8                  5                            4   \n",
      "\n",
      "    Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
      "0             1                3                1        1      2  \n",
      "1            10                3                2        1      2  \n",
      "2             2                3                1        1      2  \n",
      "3             4                3                7        1      2  \n",
      "4             1                3                1        1      2  \n",
      "..          ...              ...              ...      ...    ...  \n",
      "694           2                1                1        1      2  \n",
      "695           1                1                1        1      2  \n",
      "696           3                8               10        2      4  \n",
      "697           4               10                6        1      4  \n",
      "698           5               10                4        1      4  \n",
      "\n",
      "[683 rows x 11 columns]\n",
      "[[1.18314754 0.1599434  0.86017815 0.65133293 0.03074963 1.16182123\n",
      "  0.84028542 0.67719977 0.75028798]]\n",
      "[2 2 2 4 2 4 2 2 4 4 2 2 4 2 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 4 4 2 4 2\n",
      " 2 4 4 4 2 2 4 2 2 2 2 4 2 2 2 4 2 2 2 4 2 2 2 2 4 2 2 2 4 2 4 4 2 2 4 2 2\n",
      " 4 2 2 2 2 2 2 2 4 2 4 4 2 2 2 4 2 2 4 2 2 4 4 2 2 4 2 2 4 4 2 2 2 2 4 2 4\n",
      " 4 2 4 2 4 2 2 2 2 4 2 4 2 2 2 2 2 4 2 2 2 2 2 2 2 4 2 4 4 2 2 4 2 2 2 2 4\n",
      " 2 2 2 2 2 4 2 4 2 4 2 2 4 2 4 2 4 4 2 4 2 2 2]\n",
      "准确率： 0.9824561403508771\n",
      "[[9.51949774e-01 4.80502260e-02]\n",
      " [9.95813925e-01 4.18607470e-03]\n",
      " [9.85424692e-01 1.45753077e-02]\n",
      " [2.48854069e-02 9.75114593e-01]\n",
      " [9.97894167e-01 2.10583253e-03]\n",
      " [4.48596167e-04 9.99551404e-01]\n",
      " [9.93157014e-01 6.84298601e-03]\n",
      " [9.93252705e-01 6.74729485e-03]\n",
      " [5.44435305e-04 9.99455565e-01]\n",
      " [4.26571253e-04 9.99573429e-01]\n",
      " [9.88988158e-01 1.10118423e-02]\n",
      " [9.97029589e-01 2.97041067e-03]\n",
      " [1.16615093e-03 9.98833849e-01]\n",
      " [7.52151446e-01 2.47848554e-01]\n",
      " [9.89628968e-01 1.03710320e-02]\n",
      " [2.13904385e-03 9.97860956e-01]\n",
      " [9.89359448e-01 1.06405515e-02]\n",
      " [9.24092250e-01 7.59077500e-02]\n",
      " [9.90623983e-01 9.37601740e-03]\n",
      " [9.49600435e-01 5.03995648e-02]\n",
      " [9.82503876e-01 1.74961237e-02]\n",
      " [9.97894167e-01 2.10583253e-03]\n",
      " [9.90369042e-01 9.63095848e-03]\n",
      " [4.56862011e-01 5.43137989e-01]\n",
      " [9.28598994e-02 9.07140101e-01]\n",
      " [9.92981320e-01 7.01868044e-03]\n",
      " [9.95141882e-01 4.85811763e-03]\n",
      " [9.95920160e-01 4.07984014e-03]\n",
      " [9.38782319e-03 9.90612177e-01]\n",
      " [3.78002308e-01 6.21997692e-01]\n",
      " [9.66915359e-01 3.30846410e-02]\n",
      " [9.96800593e-01 3.19940686e-03]\n",
      " [2.23174502e-02 9.77682550e-01]\n",
      " [4.31371329e-01 5.68628671e-01]\n",
      " [9.89628968e-01 1.03710320e-02]\n",
      " [3.87676140e-01 6.12323860e-01]\n",
      " [9.93157014e-01 6.84298601e-03]\n",
      " [9.95141882e-01 4.85811763e-03]\n",
      " [2.68104754e-02 9.73189525e-01]\n",
      " [1.52794219e-03 9.98472058e-01]\n",
      " [3.58480191e-03 9.96415198e-01]\n",
      " [9.86094094e-01 1.39059063e-02]\n",
      " [9.41825133e-01 5.81748669e-02]\n",
      " [6.02494459e-04 9.99397506e-01]\n",
      " [9.92525121e-01 7.47487909e-03]\n",
      " [9.97894167e-01 2.10583253e-03]\n",
      " [9.90369042e-01 9.63095848e-03]\n",
      " [9.95141882e-01 4.85811763e-03]\n",
      " [9.32388919e-05 9.99906761e-01]\n",
      " [9.89252296e-01 1.07477035e-02]\n",
      " [9.94762356e-01 5.23764369e-03]\n",
      " [9.84310698e-01 1.56893019e-02]\n",
      " [1.93188320e-02 9.80681168e-01]\n",
      " [9.83235710e-01 1.67642904e-02]\n",
      " [9.75175897e-01 2.48241032e-02]\n",
      " [9.88832666e-01 1.11673339e-02]\n",
      " [1.39561079e-03 9.98604389e-01]\n",
      " [9.97030437e-01 2.96956256e-03]\n",
      " [9.93646944e-01 6.35305650e-03]\n",
      " [9.85424692e-01 1.45753077e-02]\n",
      " [5.29752352e-01 4.70247648e-01]\n",
      " [2.74045681e-06 9.99997260e-01]\n",
      " [9.36691777e-01 6.33082227e-02]\n",
      " [9.93646944e-01 6.35305650e-03]\n",
      " [9.84310698e-01 1.56893019e-02]\n",
      " [4.28454574e-02 9.57154543e-01]\n",
      " [9.95141882e-01 4.85811763e-03]\n",
      " [1.70207933e-03 9.98297921e-01]\n",
      " [8.48848886e-07 9.99999151e-01]\n",
      " [9.85420578e-01 1.45794220e-02]\n",
      " [9.92110347e-01 7.88965258e-03]\n",
      " [1.99845858e-03 9.98001541e-01]\n",
      " [9.77998400e-01 2.20016005e-02]\n",
      " [9.88832666e-01 1.11673339e-02]\n",
      " [1.44054727e-01 8.55945273e-01]\n",
      " [9.84310698e-01 1.56893019e-02]\n",
      " [9.88832666e-01 1.11673339e-02]\n",
      " [9.87011405e-01 1.29885952e-02]\n",
      " [9.95813925e-01 4.18607470e-03]\n",
      " [9.87288960e-01 1.27110404e-02]\n",
      " [9.95490349e-01 4.50965121e-03]\n",
      " [9.95813925e-01 4.18607470e-03]\n",
      " [4.92250987e-03 9.95077490e-01]\n",
      " [9.95872617e-01 4.12738293e-03]\n",
      " [9.61651565e-03 9.90383484e-01]\n",
      " [1.95268281e-04 9.99804732e-01]\n",
      " [9.79001601e-01 2.09983989e-02]\n",
      " [9.78883366e-01 2.11166343e-02]\n",
      " [9.45976476e-01 5.40235245e-02]\n",
      " [2.65393211e-03 9.97346068e-01]\n",
      " [9.97894167e-01 2.10583253e-03]\n",
      " [9.94989601e-01 5.01039881e-03]\n",
      " [2.73831782e-03 9.97261682e-01]\n",
      " [9.96752923e-01 3.24707687e-03]\n",
      " [9.97029589e-01 2.97041067e-03]\n",
      " [5.05735512e-02 9.49426449e-01]\n",
      " [4.07993923e-02 9.59200608e-01]\n",
      " [9.72214149e-01 2.77858510e-02]\n",
      " [9.95490349e-01 4.50965121e-03]\n",
      " [3.01460378e-02 9.69853962e-01]\n",
      " [9.95490349e-01 4.50965121e-03]\n",
      " [9.69208776e-01 3.07912243e-02]\n",
      " [1.79297534e-02 9.82070247e-01]\n",
      " [8.09231175e-04 9.99190769e-01]\n",
      " [9.72928855e-01 2.70711447e-02]\n",
      " [9.93157014e-01 6.84298601e-03]\n",
      " [9.84079196e-01 1.59208040e-02]\n",
      " [9.86874046e-01 1.31259536e-02]\n",
      " [4.51913172e-04 9.99548087e-01]\n",
      " [9.96027622e-01 3.97237848e-03]\n",
      " [1.30000893e-03 9.98699991e-01]\n",
      " [1.16358093e-01 8.83641907e-01]\n",
      " [9.77998400e-01 2.20016005e-02]\n",
      " [2.22768626e-03 9.97772314e-01]\n",
      " [9.93059975e-01 6.94002479e-03]\n",
      " [8.17960779e-03 9.91820392e-01]\n",
      " [9.85424692e-01 1.45753077e-02]\n",
      " [9.89628968e-01 1.03710320e-02]\n",
      " [9.11534521e-01 8.84654786e-02]\n",
      " [9.95141882e-01 4.85811763e-03]\n",
      " [4.86927655e-04 9.99513072e-01]\n",
      " [9.34534600e-01 6.54654002e-02]\n",
      " [9.06908853e-04 9.99093091e-01]\n",
      " [9.78547018e-01 2.14529822e-02]\n",
      " [9.95209951e-01 4.79004866e-03]\n",
      " [9.97923754e-01 2.07624644e-03]\n",
      " [9.93646944e-01 6.35305650e-03]\n",
      " [9.97030437e-01 2.96956256e-03]\n",
      " [8.46551055e-06 9.99991534e-01]\n",
      " [9.72895625e-01 2.71043750e-02]\n",
      " [9.97894167e-01 2.10583253e-03]\n",
      " [9.95490349e-01 4.50965121e-03]\n",
      " [9.95813925e-01 4.18607470e-03]\n",
      " [9.97072123e-01 2.92787702e-03]\n",
      " [9.90858144e-01 9.14185644e-03]\n",
      " [9.83828949e-01 1.61710508e-02]\n",
      " [1.10322088e-02 9.88967791e-01]\n",
      " [9.70757006e-01 2.92429943e-02]\n",
      " [1.65306693e-03 9.98346933e-01]\n",
      " [1.72126740e-01 8.27873260e-01]\n",
      " [6.88420741e-01 3.11579259e-01]\n",
      " [9.95632817e-01 4.36718308e-03]\n",
      " [1.11198081e-01 8.88801919e-01]\n",
      " [9.96800593e-01 3.19940686e-03]\n",
      " [9.92629583e-01 7.37041723e-03]\n",
      " [9.95813925e-01 4.18607470e-03]\n",
      " [9.97030437e-01 2.96956256e-03]\n",
      " [3.61431359e-05 9.99963857e-01]\n",
      " [9.97894167e-01 2.10583253e-03]\n",
      " [9.95909804e-01 4.09019569e-03]\n",
      " [9.89628968e-01 1.03710320e-02]\n",
      " [9.83346810e-01 1.66531902e-02]\n",
      " [9.56595820e-01 4.34041795e-02]\n",
      " [7.35858191e-02 9.26414181e-01]\n",
      " [9.95813925e-01 4.18607470e-03]\n",
      " [1.47112917e-05 9.99985289e-01]\n",
      " [9.83969238e-01 1.60307619e-02]\n",
      " [1.28748346e-02 9.87125165e-01]\n",
      " [9.97030437e-01 2.96956256e-03]\n",
      " [9.92629583e-01 7.37041723e-03]\n",
      " [1.32500263e-04 9.99867500e-01]\n",
      " [9.95141882e-01 4.85811763e-03]\n",
      " [2.02422968e-03 9.97975770e-01]\n",
      " [9.80445062e-01 1.95549375e-02]\n",
      " [5.89211411e-03 9.94107886e-01]\n",
      " [1.01955433e-01 8.98044567e-01]\n",
      " [9.94687961e-01 5.31203925e-03]\n",
      " [2.44251877e-01 7.55748123e-01]\n",
      " [9.85424692e-01 1.45753077e-02]\n",
      " [9.80560149e-01 1.94398512e-02]\n",
      " [9.93252705e-01 6.74729485e-03]]\n",
      "召回率：               precision    recall  f1-score   support\n",
      "\n",
      "          良性       0.97      1.00      0.99       111\n",
      "          恶性       1.00      0.95      0.97        60\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.99      0.97      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "AUC指标： 0.975\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "逻辑回归做二分类进行癌症预测（根据细胞的属性特征）\n",
    ":return: NOne\n",
    "\"\"\"\n",
    "# 构造列标签名字\n",
    "column = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "          'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli',\n",
    "          'Mitoses', 'Class']\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\",\n",
    "    names=column)\n",
    "\n",
    "print(data)\n",
    "\n",
    "# 缺失值进行处理\n",
    "data = data.replace(to_replace='?', value=np.nan)\n",
    "#直接删除，哪一行有空值，就删除对应的样本，也可以通过决策树特征推断特征\n",
    "data = data.dropna()\n",
    "print('-' * 50)\n",
    "print(data)\n",
    "# 进行数据的分割，左闭右开\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[column[1:10]], data[column[10]], test_size=0.25,\n",
    "                                                    random_state=1)\n",
    "\n",
    "# 进行标准化处理\n",
    "std = StandardScaler()\n",
    "\n",
    "x_train = std.fit_transform(x_train)\n",
    "x_test = std.transform(x_test)\n",
    "#\n",
    "# # 逻辑回归预测\n",
    "# C正则化力度，正则化强度的倒数，值越小正则化越强，高阶项系数越小\n",
    "# solver = 'liblinear'\n",
    "lg = LogisticRegression(C=0.8, solver='newton-cg')\n",
    "#\n",
    "lg.fit(x_train, y_train)\n",
    "# 逻辑回归的权重参数，了解\n",
    "print(lg.coef_)\n",
    "\n",
    "y_predict = lg.predict(x_test)\n",
    "print(y_predict)\n",
    "print(\"准确率：\", lg.score(x_test, y_test))\n",
    "print(lg.predict_proba(x_test))  #得出对应分类的概率\n",
    "# 为什么还要看下召回率，labels和target_names对应\n",
    "# macro avg 平均值  weighted avg 加权平均值\n",
    "print(\"召回率：\", classification_report(y_test, y_predict, labels=[2, 4], target_names=[\"良性\", \"恶性\"]))\n",
    "#AUC计算要求是二分类，不需要是0和1\n",
    "print(\"AUC指标：\", roc_auc_score(y_test, y_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 9)\n",
      "(171, 9)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}